{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.io import arff\n",
    "import models\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = '/home/zeyno/Desktop/Research_Topics/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.289435Z",
     "start_time": "2023-10-17T17:38:50.280424Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    #num of columns with majority NaN values\n",
    "    counter = 0\n",
    "    for column in list(df.columns):\n",
    "        #binarize the columns\n",
    "        if str(df[column][1]).startswith('b'):\n",
    "            unique = df[column].unique()\n",
    "            df[column] = df[column].map({unique[0]: 0, unique[1]: 1})\n",
    "\n",
    "        # eliminate columns with too many NaN values (optional)\n",
    "        # if df[column].isna().sum()/len(df) > 0.85:\n",
    "        #     print(\"% NaN values:\" + str(df[column].isna().sum()/len(df)))\n",
    "        #     df = df.drop([column])\n",
    "    # df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_type(df):\n",
    "    df = df.dropna()\n",
    "    last = df.columns[-1]\n",
    "    target = df[last]\n",
    "    diff = target.unique()\n",
    "    if len(diff) <= 2:\n",
    "        return \"Binary\"\n",
    "    elif len(diff) > 2:\n",
    "        return \"Multinomial\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.322430Z",
     "start_time": "2023-10-17T17:38:50.303614Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    metadata_df = pd.DataFrame()\n",
    "    num_cols = []\n",
    "    num_rows = []\n",
    "    datasets = {}\n",
    "    names = [] #only the names of the datasets that are included \n",
    "    t_type = []\n",
    "    dataset_names = [f for f in listdir(path) if isfile(join(path, f)) and f.endswith('.arff')]\n",
    "    for i in range(len(dataset_names)):\n",
    "        try:\n",
    "            data = arff.loadarff(path+'/'+dataset_names[i])\n",
    "            df = pd.DataFrame(data[0])\n",
    "            df = preprocess_dataset(df)\n",
    "            name_df = dataset_names[i].replace(\".arff\", \"\")\n",
    "            names.append(name_df)\n",
    "            datasets[name_df] = df\n",
    "            num_cols.append(df.shape[1])\n",
    "            num_rows.append(df.shape[0])\n",
    "            t_type.append(target_type(df))\n",
    "        except:\n",
    "            pass\n",
    "    metadata_df[\"name_dataset\"] = names\n",
    "    metadata_df[\"num_columns\"] = num_cols\n",
    "    metadata_df[\"num_rows\"] = num_rows\n",
    "    metadata_df[\"target_type\"] = t_type\n",
    "    return datasets, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.424587Z",
     "start_time": "2023-10-17T17:38:50.312157Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets, metadata_df = load_datasets(path)\n",
    "# metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Average Quality': -0.3465553235908145,\n",
       " 'Average Coverage': 0.017620041753653445,\n",
       " 'Average Support': 0.0,\n",
       " 'WRAcc': -0.006106319271621029,\n",
       " 'Significance': 0.09156774731314314,\n",
       " 'Confidence': 0.0,\n",
       " 'Number of Subgroups': 50,\n",
       " 'Average Length of Subgroups': 1.4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.nmeef_sd(datasets[\"tic-tac-toe\"], datasets[\"tic-tac-toe\"].columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.436661Z",
     "start_time": "2023-10-17T17:38:50.423067Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_algorithms(df, name):\n",
    "    target = df.columns[-1]\n",
    "    results = {}\n",
    "    \n",
    "    print(\"__________________________________________\")\n",
    "    print(\"START Dataset: \", name)\n",
    "    print(\"__________________________________________\")\n",
    "    \n",
    "    # # run sd\n",
    "    # sd = models.sd(df, target)\n",
    "    # print(sd.values())\n",
    "    # print(\"__________________________________________\")\n",
    "\n",
    "    #cn2_sd\n",
    "    print(\"CN2_SD\")\n",
    "    cn2_sd = models.cn2_sd(df, target).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"cn2_sd\"] = list(cn2_sd)\n",
    "\n",
    "    #run sd_map\n",
    "    print(\"SD_MAP\")\n",
    "    sd_map = models.sd_map(df, target, min_support=0.1).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"sd_map\"] = list(sd_map)\n",
    "\n",
    "    #run dssd\n",
    "    print(\"DSSD\")\n",
    "    dssd = models.dssd(df, target, min_support=0.1).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"dssd\"] = list(dssd)\n",
    "\n",
    "    #run nmeef\n",
    "    print(\"NMEEF-SD\")\n",
    "    nmeef = models.nmeef_sd(df, target).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"nnmeef\"] = list(nmeef)\n",
    "\n",
    "    #run apriori\n",
    "    print(\"Apriori-SD\")\n",
    "    a = models.apriori_sd(df, target, min_threshold = 0.1).values()\n",
    "    results[\"a\"] = list(a)\n",
    "    print(\"__________________________________________\")\n",
    "    print(\"END Dataset: \", name)\n",
    "    print(\"__________________________________________\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:49:22.603598Z",
     "start_time": "2023-10-17T17:38:50.431098Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic-tac-toe\n",
      "__________________________________________\n",
      "START Dataset:  tic-tac-toe\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  tic-tac-toe\n",
      "__________________________________________\n",
      "iris\n",
      "__________________________________________\n",
      "START Dataset:  iris\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  iris\n",
      "__________________________________________\n",
      "hayes-roth_test\n",
      "__________________________________________\n",
      "START Dataset:  hayes-roth_test\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  hayes-roth_test\n",
      "__________________________________________\n",
      "contact-lenses\n",
      "__________________________________________\n",
      "START Dataset:  contact-lenses\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  contact-lenses\n",
      "__________________________________________\n",
      "wisconsin\n",
      "__________________________________________\n",
      "START Dataset:  wisconsin\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  wisconsin\n",
      "__________________________________________\n",
      "cmc\n",
      "__________________________________________\n",
      "START Dataset:  cmc\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  cmc\n",
      "__________________________________________\n",
      "hayes-roth_train\n",
      "__________________________________________\n",
      "START Dataset:  hayes-roth_train\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  hayes-roth_train\n",
      "__________________________________________\n",
      "glass\n",
      "__________________________________________\n",
      "START Dataset:  glass\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  glass\n",
      "__________________________________________\n",
      "car\n",
      "__________________________________________\n",
      "START Dataset:  car\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  car\n",
      "__________________________________________\n",
      "pima-indians\n",
      "__________________________________________\n",
      "START Dataset:  pima-indians\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  pima-indians\n",
      "__________________________________________\n",
      "abalone\n",
      "__________________________________________\n",
      "START Dataset:  abalone\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  abalone\n",
      "__________________________________________\n",
      "balance-scale\n",
      "__________________________________________\n",
      "START Dataset:  balance-scale\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  balance-scale\n",
      "__________________________________________\n",
      "haberman\n",
      "__________________________________________\n",
      "START Dataset:  haberman\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  haberman\n",
      "__________________________________________\n",
      "zoo\n",
      "__________________________________________\n",
      "START Dataset:  zoo\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  zoo\n",
      "__________________________________________\n",
      "credit-a\n",
      "__________________________________________\n",
      "START Dataset:  credit-a\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "__________________________________________\n",
      "DSSD\n",
      "__________________________________________\n",
      "NMEEF-SD\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "__________________________________________\n",
      "END Dataset:  credit-a\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "meta_2 = {}\n",
    "for key in datasets:\n",
    "    if key in [\"dermatology\", \"labor\", \"ionosphere\", \"adult\"]:\n",
    "        continue\n",
    "    print(key)\n",
    "    results = run_algorithms(datasets[key], key)\n",
    "    meta_2[key] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Dataset Algorithm       Quality    Coverage   Support  # of Subgroups  \\\n",
      "0   tic-tac-toe    cn2_sd -5.284570e-01  478.130435  0.499092            46.0   \n",
      "1   tic-tac-toe    sd_map  8.627040e-02  199.928571  0.208694            14.0   \n",
      "2   tic-tac-toe      dssd  1.134420e-01  126.000000  0.131524             9.0   \n",
      "3   tic-tac-toe    nnmeef  5.334824e-07   22.040000  0.023006            50.0   \n",
      "4   tic-tac-toe         a           NaN    0.383917  0.133612             5.0   \n",
      "..          ...       ...           ...         ...       ...             ...   \n",
      "70     credit-a    cn2_sd -2.165685e-01  387.028571  0.560911            35.0   \n",
      "71     credit-a    sd_map -9.109338e-02  126.130841  0.182798           107.0   \n",
      "72     credit-a      dssd -8.965963e-02   93.380282  0.135334            71.0   \n",
      "73     credit-a    nnmeef  2.373177e-04    1.800000  0.002609            50.0   \n",
      "74     credit-a         a           NaN         NaN       NaN             0.0   \n",
      "\n",
      "    Length of Rules  \n",
      "0          3.521739  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3          2.060000  \n",
      "4          1.000000  \n",
      "..              ...  \n",
      "70         3.400000  \n",
      "71              NaN  \n",
      "72              NaN  \n",
      "73         2.260000  \n",
      "74              NaN  \n",
      "\n",
      "[75 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary that contains dictionaries per dataset, and the scores per algorithm.\n",
    "# For each algorithm result, the list represents the scores in these evaluation metrics:\n",
    "# Quality, Coverage, Support, number of subgroups, average length of subgroups (i.e. hte number of rules used to represent a subgroup, on average)\n",
    "meta_2\n",
    "\n",
    "# Convert the nested dictionary into a DataFrame\n",
    "df = pd.DataFrame.from_dict(meta_2, orient='index')\n",
    "df = df.stack().apply(pd.Series).reset_index()\n",
    "\n",
    "# Rename columns for clarity and reordering\n",
    "df.columns = ['Dataset', 'Algorithm', 'Quality', 'Coverage', 'Support', 'WRAcc', \"Significance\", \"Confidence\", '# of Subgroups', 'Length of Rules']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df[['Dataset', 'Algorithm', 'Quality', 'Coverage', 'Support', 'WRAcc', \"Significance\", \"Confidence\", '# of Subgroups', 'Length of Rules']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"metadata.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
