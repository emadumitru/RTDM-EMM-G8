{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.io import arff\n",
    "import models\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = '/home/zeyno/Desktop/Research_Topics/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.289435Z",
     "start_time": "2023-10-17T17:38:50.280424Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    #num of columns with majority NaN values\n",
    "    counter = 0\n",
    "    for column in list(df.columns):\n",
    "        #binarize the columns\n",
    "        if str(df[column][1]).startswith('b'):\n",
    "            unique = df[column].unique()\n",
    "            df[column] = df[column].map({unique[0]: 0, unique[1]: 1})\n",
    "\n",
    "        # eliminate columns with too many NaN values (optional)\n",
    "        # if df[column].isna().sum()/len(df) > 0.85:\n",
    "        #     print(\"% NaN values:\" + str(df[column].isna().sum()/len(df)))\n",
    "        #     df = df.drop([column])\n",
    "    # df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_type(df):\n",
    "    df = df.dropna()\n",
    "    last = df.columns[-1]\n",
    "    target = df[last]\n",
    "    diff = target.unique()\n",
    "    if len(diff) <= 2:\n",
    "        return \"Binary\"\n",
    "    elif len(diff) > 2:\n",
    "        return \"Multinomial\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.322430Z",
     "start_time": "2023-10-17T17:38:50.303614Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    metadata_df = pd.DataFrame()\n",
    "    num_cols = []\n",
    "    num_rows = []\n",
    "    datasets = {}\n",
    "    names = [] #only the names of the datasets that are included \n",
    "    t_type = []\n",
    "    dataset_names = [f for f in listdir(path) if isfile(join(path, f)) and f.endswith('.arff')]\n",
    "    for i in range(len(dataset_names)):\n",
    "        try:\n",
    "            data = arff.loadarff(path+'/'+dataset_names[i])\n",
    "            df = pd.DataFrame(data[0])\n",
    "            df = preprocess_dataset(df)\n",
    "            name_df = dataset_names[i].replace(\".arff\", \"\")\n",
    "            names.append(name_df)\n",
    "            datasets[name_df] = df\n",
    "            num_cols.append(df.shape[1])\n",
    "            num_rows.append(df.shape[0])\n",
    "            t_type.append(target_type(df))\n",
    "        except:\n",
    "            pass\n",
    "    metadata_df[\"name_dataset\"] = names\n",
    "    metadata_df[\"num_columns\"] = num_cols\n",
    "    metadata_df[\"num_rows\"] = num_rows\n",
    "    metadata_df[\"target_type\"] = t_type\n",
    "    return datasets, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.424587Z",
     "start_time": "2023-10-17T17:38:50.312157Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets, metadata_df = load_datasets(path)\n",
    "# metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Average Quality': 0.052659303549631796,\n",
       " 'Average Coverage': 83.65,\n",
       " 'Average Support': 0.08731732776617954,\n",
       " 'Number of Subgroups': 20,\n",
       " 'Average Length of Subgroups': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.dssd(datasets[\"tic-tac-toe\"], datasets[\"tic-tac-toe\"].columns[-1], min_support = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:38:50.436661Z",
     "start_time": "2023-10-17T17:38:50.423067Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_algorithms(df, name):\n",
    "    target = df.columns[-1]\n",
    "    results = {}\n",
    "    \n",
    "    print(\"__________________________________________\")\n",
    "    print(\"START Dataset: \", name)\n",
    "    print(\"__________________________________________\")\n",
    "    \n",
    "    # # run sd\n",
    "    # sd = models.sd(df, target)\n",
    "    # print(sd.values())\n",
    "    # print(\"__________________________________________\")\n",
    "\n",
    "    #cn2_sd\n",
    "    print(\"CN2_SD\")\n",
    "    cn2_sd = models.cn2_sd(df, target).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"cn2_sd\"] = list(cn2_sd)\n",
    "\n",
    "    #run sd_map\n",
    "    print(\"SD_MAP\")\n",
    "    sd_map = models.sd_map(df, target, min_support=0.1).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"sd_map\"] = list(sd_map)\n",
    "\n",
    "    #run dssd\n",
    "    print(\"DSSD\")\n",
    "    dssd = models.dssd(df, target, min_support=0.1).values()\n",
    "    print(\"__________________________________________\")\n",
    "    results[\"dssd\"] = list(dssd)\n",
    "\n",
    "    #run nmeef || havent added the evaluation metrics yet\n",
    "    # print(\"NMEEF-SD\")\n",
    "    # nmeef = models.nmeef_sd(df, target)\n",
    "    # print(nmeef)\n",
    "    # print(\"__________________________________________\")\n",
    "\n",
    "    #run apriori\n",
    "    print(\"Apriori-SD\")\n",
    "    a = models.apriori_sd(df, target, min_threshold = 0.1).values()\n",
    "    results[\"a\"] = list(a)\n",
    "    print(\"__________________________________________\")\n",
    "    print(\"END Dataset: \", name)\n",
    "    print(\"__________________________________________\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:49:22.603598Z",
     "start_time": "2023-10-17T17:38:50.431098Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic-tac-toe\n",
      "__________________________________________\n",
      "START Dataset:  tic-tac-toe\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "958\n",
      "------\n",
      "958\n",
      "902\n",
      "------\n",
      "958\n",
      "876\n",
      "------\n",
      "958\n",
      "859\n",
      "------\n",
      "958\n",
      "842\n",
      "------\n",
      "958\n",
      "825\n",
      "------\n",
      "958\n",
      "791\n",
      "------\n",
      "958\n",
      "755\n",
      "------\n",
      "958\n",
      "734\n",
      "------\n",
      "958\n",
      "715\n",
      "------\n",
      "958\n",
      "679\n",
      "------\n",
      "958\n",
      "654\n",
      "------\n",
      "958\n",
      "616\n",
      "------\n",
      "958\n",
      "594\n",
      "------\n",
      "958\n",
      "551\n",
      "------\n",
      "958\n",
      "520\n",
      "------\n",
      "958\n",
      "485\n",
      "------\n",
      "958\n",
      "457\n",
      "------\n",
      "958\n",
      "424\n",
      "------\n",
      "958\n",
      "380\n",
      "------\n",
      "958\n",
      "364\n",
      "------\n",
      "958\n",
      "332\n",
      "------\n",
      "958\n",
      "313\n",
      "------\n",
      "958\n",
      "294\n",
      "------\n",
      "958\n",
      "275\n",
      "------\n",
      "958\n",
      "233\n",
      "------\n",
      "958\n",
      "197\n",
      "------\n",
      "958\n",
      "180\n",
      "------\n",
      "958\n",
      "144\n",
      "------\n",
      "958\n",
      "99\n",
      "------\n",
      "958\n",
      "67\n",
      "------\n",
      "958\n",
      "50\n",
      "------\n",
      "958\n",
      "958\n",
      "------\n",
      "958\n",
      "__________________________________________\n",
      "SD_MAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:164: RuntimeWarning: divide by zero encountered in log\n",
      "  significance = 2 * true_positives * np.log(true_positives / (len(data[target_column]) * (len(coverage)/len(data))))\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:164: RuntimeWarning: invalid value encountered in multiply\n",
      "  significance = 2 * true_positives * np.log(true_positives / (len(data[target_column]) * (len(coverage)/len(data))))\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:239: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  TN = len(data[(~subgroup_data.index) & (data[target_column] == 0)])\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:241: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  FN = len(data[(~subgroup_data.index) & (data[target_column] == 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "__________________________________________\n",
      "DSSD\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "958\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "__________________________________________\n",
      "END Dataset:  tic-tac-toe\n",
      "__________________________________________\n",
      "iris\n",
      "__________________________________________\n",
      "START Dataset:  iris\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "100\n",
      "------\n",
      "150\n",
      "72\n",
      "------\n",
      "150\n",
      "23\n",
      "------\n",
      "150\n",
      "100\n",
      "------\n",
      "150\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:164: RuntimeWarning: divide by zero encountered in log\n",
      "  significance = 2 * true_positives * np.log(true_positives / (len(data[target_column]) * (len(coverage)/len(data))))\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:164: RuntimeWarning: invalid value encountered in multiply\n",
      "  significance = 2 * true_positives * np.log(true_positives / (len(data[target_column]) * (len(coverage)/len(data))))\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:239: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  TN = len(data[(~subgroup_data.index) & (data[target_column] == 0)])\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:241: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  FN = len(data[(~subgroup_data.index) & (data[target_column] == 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "__________________________________________\n",
      "DSSD\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "__________________________________________\n",
      "END Dataset:  iris\n",
      "__________________________________________\n",
      "hayes-roth_test\n",
      "__________________________________________\n",
      "START Dataset:  hayes-roth_test\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "27\n",
      "------\n",
      "28\n",
      "27\n",
      "------\n",
      "28\n",
      "__________________________________________\n",
      "SD_MAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:239: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  TN = len(data[(~subgroup_data.index) & (data[target_column] == 0)])\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:241: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  FN = len(data[(~subgroup_data.index) & (data[target_column] == 1)])\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:239: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  TN = len(data[(~subgroup_data.index) & (data[target_column] == 0)])\n",
      "/home/zeyno/Desktop/Research_Topics/RTDM-EMM-G8/models.py:241: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  FN = len(data[(~subgroup_data.index) & (data[target_column] == 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "__________________________________________\n",
      "DSSD\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "__________________________________________\n",
      "END Dataset:  hayes-roth_test\n",
      "__________________________________________\n",
      "contact-lenses\n",
      "__________________________________________\n",
      "START Dataset:  contact-lenses\n",
      "__________________________________________\n",
      "CN2_SD\n",
      "20\n",
      "------\n",
      "24\n",
      "__________________________________________\n",
      "SD_MAP\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "__________________________________________\n",
      "DSSD\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "__________________________________________\n",
      "Apriori-SD\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "__________________________________________\n",
      "END Dataset:  contact-lenses\n",
      "__________________________________________\n",
      "adult\n",
      "__________________________________________\n",
      "START Dataset:  adult\n",
      "__________________________________________\n",
      "CN2_SD\n"
     ]
    }
   ],
   "source": [
    "meta_2 = {}\n",
    "for key in datasets:\n",
    "    if key in [\"dermatology\", \"labor\", \"ionosphere\", \"adult\"]:\n",
    "        continue\n",
    "    print(key)\n",
    "    results = run_algorithms(datasets[key], key)\n",
    "    meta_2[key] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tic-tac-toe': {'cn2_sd': [-0.9204798598230077, 0.8632478632478633, 3, 1.0],\n",
       "  'sd_map': [-0.01905640798829651,\n",
       "   8.263157894736842,\n",
       "   0.21187584345479082,\n",
       "   19,\n",
       "   0],\n",
       "  'dssd': [-0.028846153846153806,\n",
       "   5.230769230769231,\n",
       "   0.1341222879684418,\n",
       "   13,\n",
       "   0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'iris': {'cn2_sd': [-0.25, 0.7375, 4, 2.0],\n",
       "  'sd_map': [0.35259375545089827,\n",
       "   43.77777777777778,\n",
       "   0.43777777777777777,\n",
       "   9,\n",
       "   0],\n",
       "  'dssd': [0.4450549450549451, 42.142857142857146, 0.4214285714285714, 7, 0],\n",
       "  'a': [0, 0.9854227405247814, 0.4657142857142857, 7, 1.7142857142857142]},\n",
       " 'hayes-roth_test': {'cn2_sd': [-0.9586530524674854, 1.0, 2, 1.0],\n",
       "  'sd_map': [-0.09259259259259257, 6.0, 0.22222222222222224, 6, 0],\n",
       "  'dssd': [-0.09259259259259257, 6.0, 0.22222222222222224, 6, 0],\n",
       "  'a': [0, 0.4444444444444444, 0.14814814814814814, 3, 1.0]},\n",
       " 'contact-lenses': {'cn2_sd': [-0.8904916402194913, 1.0, 1, 1.0],\n",
       "  'sd_map': [0.09230769230769231, 5.0, 0.38461538461538464, 2, 0],\n",
       "  'dssd': [0.09230769230769231, 5.0, 0.38461538461538464, 2, 0],\n",
       "  'a': [0, 0.8, 0.3076923076923077, 1, 1.0]},\n",
       " 'adult': {'cn2_sd': [-0.5732196994689286,\n",
       "   0.5543378995433791,\n",
       "   18,\n",
       "   3.6666666666666665],\n",
       "  'sd_map': [0.014527147015539357,\n",
       "   94.15384615384616,\n",
       "   0.2579557428872497,\n",
       "   13,\n",
       "   0],\n",
       "  'dssd': [0.03039433035982883, 60.625, 0.1660958904109589, 8, 0],\n",
       "  'a': [0, 0.45227473930107953, 0.18246575342465754, 5, 1.2]},\n",
       " 'wisconsin': {'cn2_sd': [-0.10810601364657141,\n",
       "   0.4712772371027474,\n",
       "   17,\n",
       "   1.9411764705882353],\n",
       "  'sd_map': [0.6083771602304966,\n",
       "   130.70623742454728,\n",
       "   0.19137077221749235,\n",
       "   497,\n",
       "   0],\n",
       "  'dssd': [0.6348033869304477, 80.4421052631579, 0.1177776065346383, 95, 0],\n",
       "  'a': [0, 0.957971530660975, 0.1822348391098335, 491, 4.3991853360488795]},\n",
       " 'cmc': {'cn2_sd': [-0.370136837513882, 0.6468646864686468, 6, 2.5],\n",
       "  'sd_map': [-0.04194434123459981,\n",
       "   23.22222222222222,\n",
       "   0.22992299229922994,\n",
       "   18,\n",
       "   0],\n",
       "  'dssd': [-0.052574900347177586, 17.0, 0.16831683168316833, 10, 0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'hayes-roth_train': {'cn2_sd': [-0.6222753871678721,\n",
       "   0.6680672268907563,\n",
       "   7,\n",
       "   2.0],\n",
       "  'sd_map': [0.0, 20.5, 0.20098039215686272, 4, 0],\n",
       "  'dssd': [0.0, 20.5, 0.20098039215686272, 4, 0],\n",
       "  'a': [0, 0.5, 0.16666666666666666, 1, 1.0]},\n",
       " 'glass': {'cn2_sd': [-0.4559171047563119,\n",
       "   0.9003831417624522,\n",
       "   3,\n",
       "   3.6666666666666665],\n",
       "  'sd_map': [-0.03289450236370774,\n",
       "   20.489795918367346,\n",
       "   0.23551489561341782,\n",
       "   49,\n",
       "   0],\n",
       "  'dssd': [-0.02790450409902465,\n",
       "   14.518518518518519,\n",
       "   0.16687952320136226,\n",
       "   27,\n",
       "   0],\n",
       "  'a': [0, 0.2504614248800295, 0.12260536398467432, 3, 1.0]},\n",
       " 'car': {'cn2_sd': [0.0, 0.8333333333333334, 3, 1.0],\n",
       "  'sd_map': [0.0, 14.439024390243903, 0.22560975609756098, 41, 0],\n",
       "  'dssd': [0.0, 9.142857142857142, 0.14285714285714285, 21, 0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'pima-indians': {'cn2_sd': [-0.47601423255179853,\n",
       "   0.5352719907407409,\n",
       "   45,\n",
       "   3.933333333333333],\n",
       "  'sd_map': [-0.21307965943340978,\n",
       "   148.54310344827587,\n",
       "   0.1934154992816092,\n",
       "   116,\n",
       "   0],\n",
       "  'dssd': [-0.21550941714125965, 122.775, 0.15986328125000002, 80, 0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'abalone': {'cn2_sd': [-2.241235443162717,\n",
       "   0.5309974980517617,\n",
       "   172,\n",
       "   3.947674418604651],\n",
       "  'sd_map': [0.8390938918157839,\n",
       "   811.1490196078431,\n",
       "   0.2861195836359235,\n",
       "   255,\n",
       "   0],\n",
       "  'dssd': [1.092123286545071, 550.8333333333334, 0.19429747207524983, 12, 0],\n",
       "  'a': [0, 0.59891102118458, 0.1705391292319396, 255, 4.015686274509804]},\n",
       " 'balance-scale': {'cn2_sd': [-0.2549687415453349,\n",
       "   0.5472434796189287,\n",
       "   19,\n",
       "   2.8947368421052633],\n",
       "  'sd_map': [-0.013101561112818707, 82.0, 0.2433234421364985, 9, 0],\n",
       "  'dssd': [-0.003966122286658237,\n",
       "   63.42857142857143,\n",
       "   0.18821534548537516,\n",
       "   7,\n",
       "   0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'haberman': {'cn2_sd': [-0.5182905766466229,\n",
       "   0.882716049382716,\n",
       "   3,\n",
       "   3.6666666666666665],\n",
       "  'sd_map': [0.12848317543969717,\n",
       "   16.666666666666668,\n",
       "   0.30864197530864196,\n",
       "   6,\n",
       "   0],\n",
       "  'dssd': [0.21043771043771042, 10.333333333333334, 0.19135802469135801, 3, 0],\n",
       "  'a': [0, 0.37959345002823264, 0.12962962962962965, 4, 1.25]},\n",
       " 'zoo': {'cn2_sd': [0.0, 1.0, 1, 1.0],\n",
       "  'sd_map': [0.0, 1.0, 0.5, 7, 0],\n",
       "  'dssd': [0.0, 1.0, 0.5, 7, 0],\n",
       "  'a': [0, nan, nan, 0, nan]},\n",
       " 'credit-a': {'cn2_sd': [-0.2137188937705454, 0.6628151260504203, 7, 3.0],\n",
       "  'sd_map': [-0.0866300899779427,\n",
       "   25.94736842105263,\n",
       "   0.19078947368421054,\n",
       "   114,\n",
       "   0],\n",
       "  'dssd': [-0.07407547571481454,\n",
       "   18.666666666666668,\n",
       "   0.13725490196078421,\n",
       "   72,\n",
       "   0],\n",
       "  'a': [0, 0.6428631311893697, 0.16176470588235292, 20, 1.6]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary that contains dictionaries per dataset, and the scores per algorithm.\n",
    "# For each algorithm result, the list represents the scores in these evaluation metrics:\n",
    "# Quality, Coverage, Support, number of subgroups, average length of subgroups (i.e. hte number of rules used to represent a subgroup, on average)\n",
    "meta_2\n",
    "\n",
    "# Convert the nested dictionary into a DataFrame\n",
    "df = pd.DataFrame.from_dict(meta_2, orient='index')\n",
    "df = df.stack().apply(pd.Series).reset_index()\n",
    "\n",
    "# Rename columns for clarity and reordering\n",
    "df.columns = ['Dataset', 'Metric', 'Algorithm', 'Quality', 'Coverage', 'Support', '# of Subgroups', 'Length of Rules']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df[['Dataset', 'Metric', 'Algorithm', 'Quality', 'Coverage', 'Support', '# of Subgroups', 'Length of Rules']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
